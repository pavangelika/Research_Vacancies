Стратегия тестирования
Цель: Обеспечить стабильность, соответствие спецификации, производительность и безопасность эндпоинта.
Принципы:
Автоматизация критически важных сценариев (contract, smoke, regression).
Ручное тестирование нового функционала.
Интеграция в CI/CD для регрессионного и контрактного тестирования.
Документация: Опираться на официальную спецификацию HH.

Тест-план с разделением по типам тестирования
0. Contract Testing (Контрактное тестирование)
Цель: Проверка соответствия API спецификации.
Когда запускать: На каждом этапе разработки, в CI/CD.
Инструменты: Pact, OpenAPI Validator, Postman Collection.
Критерии успеха:
Ответ API соответствует OpenAPI-спецификации (структура, типы данных, обязательные поля).
Нет расхождений между документацией и реальным поведением.
Контракт обновляется при изменении API.
Инструменты:
Pact (проверка контрактов между сервисами).
Dredd (валидация OpenAPI-спецификации).
OpenAPI Generator (автоматическая генерация тестов).

1. Smoke Testing (Дымовое тестирование)
Цель: Быстрая проверка основных функций после деплоя, чтобы убедиться, что API "живой".
Когда запускать:
После каждого деплоя в staging/production.
Интегрировать в pipeline: если smoke-тесты падают, блокировать релиз.
Автоматизировать базовые сценариев (например, запрос вакансий с фильтрами, и просмотр инфо о вакансии)
Критерии успеха:
Все базовые запросы возвращают 200 OK
Ответы содержат ожидаемые данные (например, не пустой массив вакансий).
Нет критических ошибок (5xx, 4xx, кроме ожидаемых).
Инструменты:
postman (автоматизированные коллекции) + Newman
pytest + requests (для запуска в CI/CD) + allure


2. Sanity Testing (Санитарное тестирование)
Цель: Проверка критических сценариев после небольших правок (например, исправление бага в фильтрации).
Когда запускать:
После мелких изменений в коде или конфигурации (багфиксы, небольшие фичи)
Фокусироваться на измененных модулях
Критерии успеха:
Конкретные изменения (например, исправление фильтрации) работают корректно
Смежные функции не сломаны (например, сортировка после правки пагинации)
Время выполнения ≤ 5 минут.
Инструменты:
postman (автоматизированные коллекции) + Newman
pytest + requests (для запуска в CI/CD) + allure

3. Regression Testing (Регрессионное тестирование)
Цель: Убедиться, что новые изменения не сломали существующий функционал.
Когда запускать: Перед каждым релизом, после крупных изменений.
Критерии успеха:
100% прохождение тестов из базового набора.
Нет регрессивных багов (все старые функции работают как раньше).
Покрытие критических сценариев ≥ 90%.
Инструменты:
pytest + Allure (отчеты о тестировании).
Selenium (для end-to-end проверок, если API связан с UI).
GitLab CI (запуск в pipeline).
Реки: Выделить "ядро" тестов (20% кейсов, покрывающих 80% функционала)

3.1. Позитивные тесты

3.2. Негативные тесты
3.2.2. проверка кодов ошибок
3.2.3. проверка граничных значений


4. Security Testing (Тестирование безопасности)
Цель: Обнаружить уязвимости в обработке параметров.
Когда запускать: Перед релизом, после изменений в аутентификации.
Критерии успеха:
Нет уязвимостей уровня High/Critical (OWASP Top 10).
Параметры корректно валидируются (SQL-инъекции, XSS, переполнение).
Rate limiting работает как задумано (например, 60 запросов в минуту).
Инструменты:
OWASP ZAP (автоматическое сканирование).
Burp Suite (ручной анализ).
nmap (проверка открытых портов, если API публичный).
Реки:  Добавить сканирование через OWASP ZAP в CI/CD.

SQL-инъекции
GET /vacancies?professional_role=124 OR 1=1
ОР: Валидация параметров → 400 Bad Request.

XSS-атаки
GET /vacancies?order_by=<script>alert(1)</script>
ОР: Экранирование спецсимволов

Переполнение параметров
GET /vacancies?work_format=A x 1000
ОР: 414 URI Too Long или 400.

4. Functional Testing (Функциональное тестирование)
Цель: Проверка всех параметров по документации.
Когда запускать: Перед релизом.
Критерии успеха:
Все параметры работают согласно документации (например, period=7 возвращает вакансии за 7 дней).
Ошибки возвращаются с корректными кодами (400 для невалидных параметров).
Фильтры и сортировка дают ожидаемый результат.
Инструменты:
Postman (ручные проверки).
pytest + jsonschema (автоматическая валидация структуры).
TestRail (трекинг тест-кейсов).
Рекомендации:
Покрыть все значения параметров из документации:
professional_role (существующие и несуществующие коды).
order_by (все допустимые значения).
Проверять логику: например, вакансии без зарплаты должны быть в конце списка при salary_desc.

5 Integration Testing (Интеграционное тестирование)
Цель: Проверка взаимодействия с другими сервисами
Когда запускать: Интегрировать в CI/CD: запускать при каждом изменении спецификации
Критерии успеха:
API корректно взаимодействует с другими сервисами (например, поиск по вакансиям + фильтрация по городам).
Обработка ошибок внешних систем (например, таймауты, 500 от зависимого сервиса).
Данные синхронизируются правильно (например, обновление вакансии в БД → отображение в API).
Инструменты:
TestContainers (запуск зависимых сервисов в контейнерах).
Postman (цепочки запросов).
WireMock (мокинг внешних API).

6. Exploratory Testing (Исследовательское тестирование)
Цель: Ручная проверка неочевидных сценариев.
Когда запускать: Проводить перед релизом в течение 1–2 часов.
Фокусироваться на:
Неочевидных комбинациях параметров (например, per_page=50 + order_by=date + period=30).
Граничных значениях (например, page=2147483647).
Использовать чек-листы для структурирования поиска.
Критерии успеха:
Обнаружены скрытые баги (например, некорректная сортировка при комбинации period=0 + order_by=salary_desc).
Сценарии, не покрытые автоматизированными тестами, протестированы.
Найденные баги задокументированы и приоритизированы.
Инструменты:
Charles Proxy / Fiddler (анализ трафика).
Notion / Jira (документирование сценариев).
Postman (ручные эксперименты с параметрами).
